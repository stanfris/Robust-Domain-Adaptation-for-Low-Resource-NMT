#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gres=gpu:1
#SBATCH --gpus=1
#SBATCH --job-name=wmt_ft_data_selection_scipar_medline_bm25
#SBATCH --ntasks=1
#SBATCH --time=04:00:00
#SBATCH --output=slurm/slurm_%A.out

module purge
module load 2024
module load Miniconda3/24.7.1-0

# Activate your environment
source activate nlp2
# Run your code
cd ../src

python -m train_data_selection --train_dataset=sethjsa/scipar_en_ru_parallel --dev_dataset=sethjsa/medline_ru_parallel --dev_split=train --output_dir=../results/wmt_ft_data_selection_scipar_medline_bm25 --warmup_steps=100 --model_name=facebook/wmt19-en-ru --reversed_model_name=facebook/wmt19-ru-en --num_train_epochs=5 --dev_sample_percentage 0.05 --save_percentage 0.20 --selection_method '5gram'
python -m evaluate_model --model_name=../results/wmt_ft_data_selection_scipar_medline_5gram --reversed_model_name=facebook/wmt19-ru-en --test_dataset=sethjsa/wmt20bio_en_ru_sent