#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gres=gpu:1
#SBATCH --gpus=1
#SBATCH --job-name=toy
#SBATCH --ntasks=1
#SBATCH --time=04:00:00
#SBATCH --output=slurm/slurm_%A.out

module purge
module load 2024
module load Miniconda3/24.7.1-0

# Activate your environment
source activate nlp2
# Run your code
cd ../src

python -m train --train_dataset=../data/mixed_dataset_selected_full --train_from_disk --output_dir=../results/less_mixed_selected_full --warmup_steps=100 --model_name=facebook/wmt19-en-ru --reversed_model_name=facebook/wmt19-ru-en --num_train_epochs=5
python -m evaluate_model --model_name=../results/less_mixed_selected_full --reversed_model_name=facebook/wmt19-ru-en --test_dataset=sethjsa/wmt20bio_en_ru_sent