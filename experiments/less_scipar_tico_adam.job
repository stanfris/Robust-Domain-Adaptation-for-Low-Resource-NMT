#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gres=gpu:1
#SBATCH --gpus=1
#SBATCH --job-name=evaluate
#SBATCH --ntasks=1
#SBATCH --time=04:00:00
#SBATCH --output=slurm/slurm_%A.out

module purge
module load 2024
module load Miniconda3/24.7.1-0

# Activate your environment
source activate nlp2
# Run your code
cd ../src

python less_selection.py --model_name=facebook/wmt19-en-ru --reversed_model_name=facebook/wmt19-ru-en --train_dataset=sethjsa/scipar_en_ru_parallel --dev_dataset=sethjsa/tico_en_ru --output_dir=../grads/scipar_adam_for_tico --dataset_output_dir=../data/scipar_selected_adam_for_tico --use_adam
python -m train --train_dataset=../data/scipar_selected_adam_for_tico --train_from_disk --pretrain_dataset=../data/scipar_selected_adam_for_tico_pretrain_subset --pretrain_from_disk --output_dir=../results/scipar_selected_adam_for_tico --warmup_steps=100 --model_name=facebook/wmt19-en-ru --reversed_model_name=facebook/wmt19-ru-en --num_train_epochs=5
python -m evaluate_model --model_name=../results/scipar_selected_adam_for_tico --reversed_model_name=facebook/wmt19-ru-en --test_dataset=sethjsa/wmt20bio_en_ru_sent